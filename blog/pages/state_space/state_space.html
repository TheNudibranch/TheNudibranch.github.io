<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>An Unhinged Introduction to State Space Models with STAN</title>

<script src="site_libs/header-attrs-2.11/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>




<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
	<a class="navbar-brand" href="../../../index.html">Ian Costley Homepage</a>
  <div class="container">
  	<!-- <a class="navbar-brand" href="../../../index.html">Ian Costley Homepage</a> -->
    <div class="navbar-header">
      <!-- NOTE: add "navbar-inverse" class for an alternate navbar background -->
      <!-- <a class="navbar-brand" href="../../../index.html">Ian Costley Homepage</a> -->
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li><a href="https://github.com/TheNudibranch">GitHub</a></li>
        <li><a href="https://www.linkedin.com/in/ian-s-costley/">LinkedIn</a></li>
        <li><a href="../../blog.html">B<sub>natural</sub>LOG</a></li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">An Unhinged Introduction to State Space
Models with STAN</h1>

</div>


<style type="text/css">
pre {
  max-height: 200px;
  overflow-y: auto;
}

pre[class] {
  max-height: 500px;
}

.scroll-100 {
  max-height: 100px;
  overflow-y: auto;
  background-color: inherit;
}
</style>
<div id="casting-calls" class="section level1">
<h1>Casting Calls</h1>
<div id="motivation-more-ice-please" class="section level2">
<h2>Motivation: More Ice Please</h2>
<p>Let’s say you work for a drinkware company, we’ll call it something
generic, maybe “<strong>L</strong>arge bi-p<strong>E</strong>dal
s<strong>N</strong>ow crypt<strong>I</strong>d”? Or LENI for short. LENI
sells mugs, wine glasses, water glasses, and tumblers. The recent lack
of innovation in the tumbler market has led to public outcry. As a
response, you release Tumbler v2™. This exciting new technology features
the same size tumblers you know an love, but with double the ice
capacity. You even come up with a catchy slogan:</p>
<center>
<em>“Double the ice, for the exact same price.” - LENI</em>
</center>
<p>As a result of your genius ideas, your tumbler sales being to pick
up:</p>
<p><img src="state_space_files/figure-html/unnamed-chunk-4-1.png" width="960" style="display: block; margin: auto;" /></p>
</div>
<div id="the-final-frontier" class="section level2">
<h2>The final frontier</h2>
<p>Your tumbler sales are putting all your rival drinkware companies,
like “Abominable Snowman”, to shame. But just how much of your sales are
incremental and aren’t just due to the usual seasonality, or positive
overall industry growth. Can you quantify with some degree of certain
the incremental sales you’ve realized from launching Tumbler v2™?</p>
<p>To approach this problem, we will use state space models. A class of
models that assumes that our data generating process has some underlying
state that gives rise to our actually observed variables. For instance,
in the time series plot above, a state space approach would assume that
each point in the time series is generated from some latent unobserved
state which has its own distribution. For this time series analysis
state space problem, we will used the widely adopted and used approach
of <span class="citation">(James Durbin and Koopman 2012)</span>. The
governing equation for this system is given by:</p>
<p><span class="math display">\[\begin{align}
y_t &amp;= Z_t\alpha_t + \varepsilon_t\\
\alpha_{t+1} &amp;= T_t \alpha_t + R_t \eta_t
\end{align}\]</span></p>
<p>where</p>
<p><span class="math display">\[\varepsilon_t \sim \mathcal{N}(0,H_t)
\hspace{2mm} \text{and} \hspace{2mm} \eta_t \sim
\mathcal{N}(0,Q_t)\]</span> You might only recognize <span
class="math inline">\(y_t\)</span>, the sales from our Tumbler v2, from
the equation above. But allow me to introduce the full cast of
characters:</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Vectors
</div>
</th>
<th style="border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="3">
<div style="border-bottom: 1px solid #ddd; padding-bottom: 5px; ">
Matricies
</div>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
<span class="math inline">\(y_t\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p \times 1\)</span>
</td>
<td style="text-align:left;">
Observations
</td>
<td style="text-align:left;">
<span class="math inline">\(Z_t\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p \times m\)</span>
</td>
<td style="text-align:left;">
Design Matrix
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\alpha_t\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(m \times 1\)</span>
</td>
<td style="text-align:left;">
(Latent) State
</td>
<td style="text-align:left;">
<span class="math inline">\(T_t\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(m \times m\)</span>
</td>
<td style="text-align:left;">
Transition Matrix
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\varepsilon_t\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p \times 1\)</span>
</td>
<td style="text-align:left;">
Obs. Disturbance
</td>
<td style="text-align:left;">
<span class="math inline">\(H_t\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(p \times p\)</span>
</td>
<td style="text-align:left;">
Obs. Covariance Matrix
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(\eta_t\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(r \times 1\)</span>
</td>
<td style="text-align:left;">
State Disturbance
</td>
<td style="text-align:left;">
<span class="math inline">\(R_t\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(m \times r\)</span>
</td>
<td style="text-align:left;">
State Disturbance Selection Matrix
</td>
</tr>
<tr>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
</td>
<td style="text-align:left;">
<span class="math inline">\(Q_t\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(r \times r\)</span>
</td>
<td style="text-align:left;">
State Covariance Matrix
</td>
</tr>
<tr>
<td style="text-align:left;">
<span class="math inline">\(a_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(m \times 1\)</span>
</td>
<td style="text-align:left;">
Initial State Expected Value
</td>
<td style="text-align:left;">
<span class="math inline">\(P_1\)</span>
</td>
<td style="text-align:left;">
<span class="math inline">\(m \times m\)</span>
</td>
<td style="text-align:left;">
Initial State Covariance Matrix
</td>
</tr>
</tbody>
</table>
<p>Here <span class="math inline">\(\alpha_t\)</span> is the underlying
latent state that gives rise to our time series realizations <span
class="math inline">\(y_t\)</span>. As stated before, the latent state
<span class="math inline">\(\alpha_t\)</span> has its own distribution,
which we can now deduce from the equation above is given by <span
class="math inline">\(\alpha_t \sim \mathcal{N}(a_t, Q_t)\)</span>.
Notice from our table above that <span
class="math inline">\(\alpha_t\)</span> is not the same size as <span
class="math inline">\(y_t\)</span>. Our observations <span
class="math inline">\(y_t\)</span> is a vector of length <span
class="math inline">\(p\)</span>, which will be 1 for our case here.
Conversely, <span class="math inline">\(\alpha_t\)</span> is of size
<span class="math inline">\(m\)</span>. This is because <span
class="math inline">\(\alpha_t\)</span> will act as the conduit for all
the effects and assumptions we impose on the model.</p>
<p>This is one of the best utilities provided by state space models. We
have the ability to add smaller effects together and extract them at the
end of the modeling process to further understand the structure of our
time series. For example, you might want to impose a 52 week seasonality
(1 year), positive industry trend growth, additive regression effects,
and maybe even a AR(n) process to account for autocorrelation. All of
this information is packed in <span
class="math inline">\(\alpha_t\)</span> which we’ll demonstrate
later.</p>
<p>The matrix <span class="math inline">\(Z_t\)</span> provides the
translation from <span class="math inline">\(\mathbb{R}^m\)</span> to
<span class="math inline">\(\mathbb{R}^p\)</span>, which our case is
just one dimension. Therefore, <span class="math inline">\(Z_t\)</span>
reduces down to a vector of length <span
class="math inline">\(m\)</span>, but this is not the case in general.
Some of the data that <span class="math inline">\(Z_t\)</span> might
hold is the <span class="math inline">\(x_t\)</span> for the regression
component of our time series. Usually, <span
class="math inline">\(Z_t\)</span> is filled with 1s and 0s to select
different components of <span class="math inline">\(\alpha_t\)</span>
that are used for <span class="math inline">\(y_t\)</span>. As we’ll see
later, there are many components of <span
class="math inline">\(\alpha_t\)</span> that don’t directly impact <span
class="math inline">\(y_t\)</span>, but are strategically placed to help
<span class="math inline">\(\alpha_t\)</span> itself evolve over
time.</p>
<p>This is a great segue to our transition matrix <span
class="math inline">\(T_t\)</span>. The transition matrix is what
evolves <span class="math inline">\(\alpha_t\)</span> to the next state
<span class="math inline">\(\alpha_{t+1}\)</span>. This again can take
multiple forms. It might be the stage in the process where a positive
industry trend is added to the overall series or where we move from
season to season.</p>
<p>Finally we have <span class="math inline">\(R_t\)</span>, the state
disturbance selection matrix. Notice that everything up to this point
has had a <span class="math inline">\(t\)</span> subscript. While we are
modeling a time series, it is not true that every element of <span
class="math inline">\(\alpha_t\)</span> has to vary over time. In fact,
most of the time the regression coefficients (if included) are usually
static with respect to time. The way we tell this model to account for
static elements of <span class="math inline">\(\alpha_t\)</span> is to
not add any disturbance to them. Lets consider a very simple local
linear trend model:</p>
<p><span class="math display">\[\begin{align}
y_t &amp;= \mu_t + \varepsilon_t\\
\mu_{t + 1} &amp;= \mu_{t} + \nu_{t} + \eta_{t}\\
\nu_{t+1} &amp;= \nu_{t}
\end{align}\]</span></p>
<p>Our cast of characters now wear the following costumes:</p>
<p><span class="math display">\[\alpha_t = \begin{bmatrix} \mu_t \\
\nu_t\end{bmatrix} \hspace{10mm} Z_t = \begin{bmatrix} 1 &amp; 0\\
\end{bmatrix}\]</span> <span class="math display">\[T_t =
\begin{bmatrix}1 &amp; 1\\ 0 &amp; 1 \end{bmatrix} \hspace{5mm} R_t =
\begin{bmatrix}1\\ 0\end{bmatrix}\]</span> Clearly, <span
class="math inline">\(\eta_t\)</span> is just a 1-D normal with variance
<span class="math inline">\(Q_t\)</span>, and thus as <span
class="math inline">\(\alpha_t\)</span> evolves over time its element
<span class="math inline">\(\nu_{n+1} = \nu_{n}\)</span> for all <span
class="math inline">\(n\in [1,t]\)</span>. The variable <span
class="math inline">\(\nu\)</span> here could be considered a static
industry trend and <span class="math inline">\(\mu_t\)</span> is the
random walk it perturbs. I’m sure you can already see the powerful
flexibility we’ve been afforded by this modeling system.</p>
<p>Now, the only variables I have yet to mention are <span
class="math inline">\(a_1\)</span> and <span
class="math inline">\(P_1\)</span>. These dictate the distribution of
our starting state. That is <span class="math inline">\(\alpha_1 \sim
\mathcal{N}(a_1, P_1)\)</span>. These initial values are assumed to be
known at the time of modeling. In reality these are rarely known and
there is a large amount of theory to approximate the best starting value
of these based on asymptotics. For more information, check out chapter 5
of <span class="citation">(James Durbin and Koopman 2012)</span>. But,
we are Bayesians after all are we not? If we don’t know something we
just chuck a prior at it. Although we will abide by the suggestion in
chapter 5 and set <span class="math inline">\(a_1 = \bf{0}\)</span>.</p>
</div>
<div id="i-prefer-autumn" class="section level2">
<h2>I prefer Autumn</h2>
<p>One of the key components we’ll utilize is seasonality. This means
that for some repeating point in time, we want to see the same, or
slightly modified effect. For example, we might observe seasonality in
consumer purchasing behavior. Big spikes occur during the holidays when
everyone is purchasing Tumbler v2s to give to their ice enthusiast
friends at Christmas, but then sales slowly die off. It’s a tale as old
as time that we’ll see again next Christmas.</p>
<p>We’ll go about this by considering a 4 season example. This might be
data that is collected every quarter for a company. We’ll define four
season parameters denoted by <span
class="math inline">\(\tau_j\)</span>, where <span
class="math inline">\(j \in [1,4]\)</span>. We’ll make the assumption
that all seasonal effects will add to zero. This makes sense if we
assume that a seasonal effect is just some perturbation against the
underlying trend. Consider the following:</p>
<p><img src="state_space_files/figure-html/unnamed-chunk-6-1.png" width="1152" style="display: block; margin: auto;" /></p>
<p>Let’s write our system in plain Greek and forget about the matrices
for a second:</p>
<p><span class="math display">\[\begin{align}
y_t &amp;= \mu_t + \tau_t + \varepsilon_t\\
\mu_{t + 1} &amp;= \mu_{t} + \eta_{t}^\mu\\
\tau_{t+1} &amp;= -\sum_{j=1}^{s-1}\tau_{t + 1 - j} + \eta_t^\tau
\end{align}\]</span></p>
<p>For some, that summation might have come out of left field. But
recall that we defined our seasonality components to sum to zero.
Therefore, for any <span class="math inline">\(s\)</span> length
seasonality trend, we only need <span class="math inline">\(s-1\)</span>
components to recover the full trend. For example if we have a seasonal
trend of length 4 and trying to find the expected seasonal component of
time <span class="math inline">\(t+1\)</span>, we can use the
following:</p>
<p><span class="math display">\[\begin{align}
0 &amp;= \tau_{t+1} + \tau_{t} + \tau_{t-1} + \tau_{t-2}\\
\tau_{t+1} &amp;= -(\tau_{t} + \tau_{t-1} + \tau_{t-2})\\
\tau_{t+1} &amp;= -\sum_{j=1}^{s-1}\tau_{t + 1 - j}\\
\end{align}\]</span></p>
<p>Since we want to allow our seasonality to vary over time, we add a
disturbance <span class="math inline">\(\eta_t^\tau\)</span> every time
the next expected seasonality component <span
class="math inline">\(\tau_{t+1}\)</span> is calculated. Note, since we
want both <span class="math inline">\(\mu_t\)</span> and <span
class="math inline">\(\tau_t\)</span> to vary over time, <span
class="math inline">\(\eta_t\)</span> will be a vector of length 2.
Finally, we can write our state space system matrices as:</p>
<p><span class="math display">\[\alpha_t = \begin{bmatrix} \mu_t \\
\tau_{t} \\ \tau_{t-1} \\ \tau_{t-2}\end{bmatrix} \hspace{10mm} Z_t =
\begin{bmatrix} 1 &amp; 1 &amp; 0 &amp; 0\\ \end{bmatrix}\]</span> <span
class="math display">\[T_t = \begin{bmatrix}1 &amp; 0 &amp; 0 &amp; 0\\
0 &amp; -1 &amp; -1 &amp; -1\\0 &amp; 1 &amp; 0 &amp; 0\\0 &amp; 0 &amp;
1 &amp; 0\end{bmatrix} \hspace{5mm} R_t = \begin{bmatrix}1 &amp; 0\\ 0
&amp; 1\\0 &amp;0\\0&amp;0\end{bmatrix}\]</span> The 1s in the third and
fourth row of <span class="math inline">\(T_t\)</span> ensure that we
carry the <span class="math inline">\(s-2\)</span> most recent seasonal
components with us to the next state. The 0s in the third and fourth row
of <span class="math inline">\(R_t\)</span> <em>select</em> our
disturbance draw such that no variation will be applied to the <span
class="math inline">\(s-2\)</span> carryover seasonal states.</p>
</div>
</div>
<div id="setting-the-stage" class="section level1">
<h1>Setting the Stage</h1>
<div id="mine-is-a-brita" class="section level2">
<h2>Mine is a Brita</h2>
<p>The first step of our modeling process is
<strong>filtering</strong>.</p>
<p>For sake of completeness, let’s review the assumptions<a href="#fn1"
class="footnote-ref" id="fnref1"><sup>1</sup></a> we made about our data
generating process by imposing this system of equations:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(y_t\)</span> is a linear function of the
latent state <span class="math inline">\(\alpha_t\)</span></li>
<li>The disturbances of our data generating process are normally
distributed</li>
<li>The disturbances of our latent state are normally distributed.</li>
</ol>
<p>These unassuming<a href="#fn2" class="footnote-ref"
id="fnref2"><sup>2</sup></a> assumptions allow us to now leverage the
power of the <a
href="https://www.kalmanfilter.net/background.html">Kalman filter</a>.
Without going into too much detail, filtering is just the process of
updating what we expect given what we have observed. Assume that we have
seen the first 4 realizations of some time series process. We are not in
the dark about. We have <em>some</em> knowledge about what the 5th
observation might be. If the first 4 had values between 1 and 10, we can
be pretty sure that the 5th realization won’t be 1,000. This is of
course a gross oversimplification, but if our process follows the
assumptions outlined above, we can use the Kalman filter to quantify the
uncertainty and expected value of our 5th observation.</p>
<p>If we had the time I would write out the derivation for you, but I
already feel like I’m going to write too much. Instead, I refer you to
page 82-85 of <span class="citation">(James Durbin and Koopman
2012)</span> or this <a
href="https://nrotella.github.io/journal/kalman-filter-derivation-interpretation.html">cool
blog post</a>. Now, you’ve met the star cast but do you know their
origin story:</p>
<p><span class="math display">\[
\begin{align*}
v_t &amp;= y_t - Z_ta_t &amp; F_t &amp;= Z_t P_t Z^\prime_t + H_t \\
a_{t|t} &amp;= a_t + P_t Z^\prime_t F^{-1}_t v_t &amp; P_{t|t} &amp;=
P_t - P_t Z^\prime_t F^{-1}_t Z_t P_t \\
a_{t+1} &amp;= T_t a_t + K_t v_t &amp; P_{t+1} &amp;= T_t P_t (T_t - K_t
Z_t)^\prime + R_t Q_t R^\prime_t
\end{align*}
\]</span> Looks like we picked up some side characters on the way. The
matrix <span class="math inline">\(K_t\)</span> is referred to as the
Kalman Gain and is given by <span class="math inline">\(K_t =
T_tP_tZ^\prime_tF^{-1}_t\)</span>. It encodes how much we should trust a
given observation <span class="math inline">\(y_t\)</span>. If the gain
is high, then the observation uncertainty is low and the next predicted
state has a high dependence on the previous observation. If the gain is
low, there is high uncertainty in the observation and thus we put most
of our faith in the previous predicted state <span
class="math inline">\(a_t\)</span>. For a more detailed inerpretation,
take a look at this <a
href="https://dsp.stackexchange.com/questions/2347/how-to-understand-kalman-gain-intuitively">stackoverflow
post</a>.</p>
<p>The matrix <span class="math inline">\(F_t\)</span> is defined as
<span class="math inline">\(\textrm{Var}[v_t|Y_{t-1}]\)</span> and the
conditional expected value and variance of the state is defined as:</p>
<p><span class="math display">\[
\begin{align*}
a_{t|t}&amp;=\mathbb{E}[\alpha_t|Y_t] &amp;
P_{t|t}&amp;=\textrm{Var}[\alpha_t|P_t] \\
\end{align*}
\]</span> In practice, you can actually ignore the middle row (<span
class="math inline">\(*_{t|t}\)</span>) but we include it for
completeness.</p>
</div>
<div id="dont-forget-to-moisturize" class="section level2">
<h2>Don’t forget to Moisturize</h2>
<p>So you’ve done your filtering, but we don’t want dry flaky equations.
For that you’re going to need to moisturize, or as the mathematicians
call it: <strong>smoothing</strong>. You can think of filtering as the
forward pass and smoothing as the backward pass. Filtering helped us get
the finish line and find the next expected quantity given what we have
seen so far. But now that we are at the final time step, we can go
backwards and update our states with the entire series of observations,
<span class="math inline">\(Y_n\)</span>. There are smoothing equations
for the smoothed disturbances of <span
class="math inline">\(\varepsilon_t\)</span> and <span
class="math inline">\(\eta_t\)</span>, which we will denote <span
class="math inline">\(\hat{\varepsilon}_t\)</span> and <span
class="math inline">\(\hat{\eta}_t\)</span> respectively, but we will
omit those since we are only concerned with the smoothed state <span
class="math inline">\(\hat{\alpha}_t\)</span> inference.</p>
<p>We define <span class="math inline">\(\hat{\alpha}_t =
\mathbb{E}[\alpha_t|Y_n]\)</span>. Note, this is different from <span
class="math inline">\(a_{t|t}\)</span> in filtering due to the
condition. The series <span class="math inline">\(Y_t\)</span> is
defined as the series of observations up to time <span
class="math inline">\(t\)</span> given by <span
class="math inline">\(Y_t = \{y_0, y_1, \dots,y_t\}\)</span>, but <span
class="math inline">\(Y_n\)</span> is the entire series of <span
class="math inline">\(n\)</span> observations. As with filtering, I omit
the proof of the smoothing equations and instead refer you to pages
88-91 of <span class="citation">(James Durbin and Koopman 2012)</span>.
The smoothing equations are relatively simpler, given by</p>
<p><span class="math display">\[
\begin{align*}
r_{t-1} &amp;= Z_t^\prime F_t^{-1} v_t + L_t^\prime r_t &amp;
\hat{\alpha_t} &amp;= a_t + P_t r_{t-1}
\end{align*}
\]</span> What fresh hell is this? We just keep getting more and more
cast members? I promise, this was the last audition, they’ll be no more
late additions. The matrix <span class="math inline">\(L_t\)</span> is
present only for convenience and is defined as <span
class="math inline">\(L_t = T_t - K_t Z_t\)</span>. As I said before,
this is the backward pass. When we start to compute our smoothed states,
we will go in reverse following <span
class="math inline">\(t=n,\dots,1\)</span>, with <span
class="math inline">\(r_n = 0\)</span>.</p>
</div>
<div id="kinda-like-understudies" class="section level2">
<h2>Kinda like Understudies</h2>
<p>Alright, so we went forward, we went backward, what’s left before
show time? <strong>Simulating</strong>. I’m not one for point estimates.
If given the option I’d rather work with a distribution, which works
nicely with our chosen Bayesian workflow. Our distribution of interest
is <span class="math inline">\(P(\alpha_t|Y_n)\)</span>, with individual
draws denoted as <span class="math inline">\(\tilde{\alpha}_t\)</span>.
How do we go about sampling this? Luckily, Durbin and Koopman have us
covered once again <span class="citation">(J. Durbin and Koopman
2002)</span>.</p>
</div>
</div>
<div id="its-showtime" class="section level1">
<h1>Its Showtime!</h1>
<pre class="r"><code>sessionInfo()</code></pre>
<pre><code>## R version 4.1.1 (2021-08-10)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19045)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_United States.1252 
## [2] LC_CTYPE=English_United States.1252   
## [3] LC_MONETARY=English_United States.1252
## [4] LC_NUMERIC=C                          
## [5] LC_TIME=English_United States.1252    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] kableExtra_1.3.4 cmdstanr_0.5.3  
## 
## loaded via a namespace (and not attached):
##  [1] tidyselect_1.1.1     xfun_0.27            bslib_0.3.1         
##  [4] purrr_0.3.4          colorspace_2.0-2     vctrs_0.4.1         
##  [7] generics_0.1.1       htmltools_0.5.2      viridisLite_0.4.0   
## [10] yaml_2.2.1           utf8_1.2.2           rlang_1.0.3         
## [13] jquerylib_0.1.4      pillar_1.6.4         glue_1.6.2          
## [16] DBI_1.1.3            distributional_0.3.1 lifecycle_1.0.1     
## [19] stringr_1.4.0        posterior_1.3.1      munsell_0.5.0       
## [22] gtable_0.3.0         rvest_1.0.2          evaluate_0.14       
## [25] knitr_1.36           fastmap_1.1.0        fansi_0.5.0         
## [28] highr_0.9            scales_1.1.1         backports_1.4.1     
## [31] checkmate_2.0.0      webshot_0.5.4        jsonlite_1.7.2      
## [34] abind_1.4-5          farver_2.1.0         systemfonts_1.0.4   
## [37] tensorA_0.36.2       ggplot2_3.3.5        digest_0.6.28       
## [40] stringi_1.7.5        dplyr_1.0.9          grid_4.1.1          
## [43] cli_3.3.0            tools_4.1.1          magrittr_2.0.1      
## [46] sass_0.4.0           tibble_3.1.6         crayon_1.4.2        
## [49] pkgconfig_2.0.3      ellipsis_0.3.2       xml2_1.3.3          
## [52] assertthat_0.2.1     rmarkdown_2.11       svglite_2.1.0       
## [55] httr_1.4.3           rstudioapi_0.13      R6_2.5.1            
## [58] compiler_4.1.1</code></pre>
<div id="references" class="section level2">
<h2>References</h2>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-book" class="csl-entry">
Durbin, James, and Siem Jan Koopman. 2012. <em><span class="nocase">Time
Series Analysis by State Space Methods</span></em>. Oxford University
Press. <a
href="https://doi.org/10.1093/acprof:oso/9780199641178.001.0001">https://doi.org/10.1093/acprof:oso/9780199641178.001.0001</a>.
</div>
<div id="ref-sim_paper" class="csl-entry">
Durbin, J., and S. J. Koopman. 2002. <span>“A Simple and Efficient
Simulation Smoother for State Space Time Series Analysis.”</span>
<em>Biometrika</em> 89 (3): 603–15. <a
href="http://www.jstor.org/stable/4140605">http://www.jstor.org/stable/4140605</a>.
</div>
</div>
</div>
</div>
<div class="footnotes footnotes-end-of-document">
<hr />
<ol>
<li id="fn1"><p>You can actually drop the normality assumptions of the
disturbances if you’re willing to work with the <em>minimum variance
linear unbiased estimate</em> (MVLUE) instead<a href="#fnref1"
class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Or incredibly assuming<a href="#fnref2"
class="footnote-back">↩︎</a></p></li>
</ol>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
